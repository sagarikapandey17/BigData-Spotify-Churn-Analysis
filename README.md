# BigData-Spotify-Churn-Analysis
Project Overview

The Big Data Spotify Churn Analysis project analyzes large-scale user interaction data to predict user churn (users who stop using the service) on Spotify. Using Hadoop and MapReduce in Java, this project focuses on processing key-value pairs from large datasets to identify patterns and trends that lead to churn. The analysis is purely focused on distributed data processing using the Hadoop ecosystem and Java.

Features

Data storage and processing using Hadoop HDFS and MapReduce.
Analyze user interaction patterns using key-value pair mapping.
Calculate churn rates based on user behavior and interactions.
Aggregate data at scale using MapReduce for distributed processing.
Simple and efficient Hadoop MapReduce jobs written in Java for churn analysis.
Technologies Used

Hadoop HDFS: Distributed file system for storing large datasets.
Hadoop MapReduce: Framework for processing large data sets in parallel using Map and Reduce steps.
Java: Programming language for writing MapReduce jobs (key-value pair processing).
Apache Hive (optional): For querying data stored in Hadoop.
Apache Pig (optional): For processing data stored in HDFS.
Jupyter Notebooks (optional for post-processing visualization, but not necessary if you are only using MapReduce).
Getting Started

Prerequisites
Hadoop installed and configured (HDFS and MapReduce).
Java 8 or higher installed for writing and running MapReduce jobs.
Basic understanding of Hadoop MapReduce and HDFS.
Hive or Pig installed (optional, for querying large datasets in Hadoop).
Installing Required Libraries
Clone the repository:
git clone https://github.com/sagarikapandey17/BigData-Spotify-Churn-Analysis.git
cd BigData-Spotify-Churn-Analysis
